{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import argparse\n",
    "import document_pb2\n",
    "import struct\n",
    "import gzip\n",
    "import sys\n",
    "import array\n",
    "import os\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYMORPHY_CACHE = {}\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "#help funcs\n",
    "def pymorphy_tokenizer(text):\n",
    "    global PYMORPHY_CACHE\n",
    "\n",
    "    for word in text:\n",
    "        word_hash = hash(word)\n",
    "        if word_hash not in PYMORPHY_CACHE:\n",
    "            PYMORPHY_CACHE[word_hash] = morph.parse(word)[0].normal_form            \n",
    "        yield PYMORPHY_CACHE[word_hash]\n",
    "        \n",
    "def union(arr1, arr2):\n",
    "    m, n, i, j = len(arr1), len(arr2), 0, 0\n",
    "    result = []\n",
    "    \n",
    "    while i < m and j < n: \n",
    "        if arr1[i] < arr2[j]: \n",
    "            result.append(arr1[i]) \n",
    "            i += 1\n",
    "        elif arr2[j] < arr1[i]: \n",
    "            result.append(arr2[j]) \n",
    "            j+= 1\n",
    "        else: \n",
    "            result.append(arr2[j]) \n",
    "            j += 1\n",
    "            i += 1\n",
    "  \n",
    "    while i < m: \n",
    "        result.append(arr1[i]) \n",
    "        i += 1\n",
    "    while j < n: \n",
    "        result.append(arr2[j]) \n",
    "        j += 1\n",
    "        \n",
    "    return result\n",
    "        \n",
    "def intersection(arr1, arr2): \n",
    "    m, n, i, j = len(arr1), len(arr2), 0, 0\n",
    "    result = []\n",
    "    \n",
    "    while i < m and j < n: \n",
    "        if arr1[i] < arr2[j]: \n",
    "            i += 1\n",
    "        elif arr2[j] < arr1[i]: \n",
    "            j += 1\n",
    "        else: \n",
    "            result.append(arr2[j]) \n",
    "            j += 1\n",
    "            i += 1\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Varbyte:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def pack(self, numbers):\n",
    "        bytes_list = []\n",
    "        for number in numbers:\n",
    "            bytes_list.append(self.encode_number(number))\n",
    "        return b''.join(bytes_list)\n",
    "    \n",
    "    def encode_number(self, number):\n",
    "        bytes_list = []\n",
    "        while True:\n",
    "            bytes_list.insert(0, number % 128)\n",
    "            if number < 128:\n",
    "                break\n",
    "            number = number // 128\n",
    "        bytes_list[-1] += 128\n",
    "        return struct.pack('%dB' % len(bytes_list), *bytes_list)\n",
    "        \n",
    "    def unpack(self, packed):\n",
    "        n = 0\n",
    "        numbers = []\n",
    "        bytestream = struct.unpack('%dB' % len(packed), packed)\n",
    "        for byte in bytestream:\n",
    "            if byte < 128:\n",
    "                n = 128 * n + byte\n",
    "            else:\n",
    "                n = 128 * n + (byte - 128)\n",
    "                numbers.append(n)\n",
    "                n = 0\n",
    "        return numbers\n",
    "    \n",
    "#почему-то он не сжимает сильно лучше Varbyte...\n",
    "class Simple9:\n",
    "    def __init__(self):\n",
    "        self.code = {1 : 0, 2 : 1, 3 : 2, 4 : 3, 5 : 4, 7 : 5, 9 : 6, 14 : 7, 28 : 8}\n",
    "        self.coded = {0 : 1, 1 : 2, 2 : 3, 3 : 4, 4 : 5, 5 : 7, 6 : 9, 7 : 14, 8 : 28}\n",
    "\n",
    "    def encode_chunk(self, numbers):\n",
    "        n, length = 0, len(numbers)\n",
    "        n = int(self.code[length] << 28)\n",
    "        for i in range(length):\n",
    "            n += numbers[i] << ((28 // length) * i)\n",
    "        \n",
    "        return struct.pack('I', n)\n",
    "    \n",
    "    def pack(self, numbers):\n",
    "        bytes_list = []\n",
    "        \n",
    "        n, length = 0, len(numbers)\n",
    "        while n < length:\n",
    "            if n + 28 <= length and max(numbers[n:n + 28:]) <= 1:\n",
    "                bytes_list.append(self.encode_chunk(numbers[n:n + 28:]))\n",
    "                n += 28\n",
    "            elif n + 14 <= length and max(numbers[n:n + 14:]) <= 3:\n",
    "                bytes_list.append(self.encode_chunk(numbers[n:n + 14:]))\n",
    "                n += 14\n",
    "            elif n + 9 <= length and max(numbers[n:n + 9:]) <= 7:\n",
    "                bytes_list.append(self.encode_chunk(numbers[n:n + 9:]))\n",
    "                n += 9\n",
    "            elif n + 7 <= length and max(numbers[n:n + 7:]) <= 15:\n",
    "                bytes_list.append(self.encode_chunk(numbers[n:n + 7:]))\n",
    "                n += 7\n",
    "            elif n + 5 <= length and max(numbers[n:n + 5:]) <= 31:\n",
    "                bytes_list.append(self.encode_chunk(numbers[n:n + 5:]))\n",
    "                n += 5\n",
    "            elif n + 4 <= length and max(numbers[n:n + 4:]) <= 127:\n",
    "                bytes_list.append(self.encode_chunk(numbers[n:n + 4:]))\n",
    "                n += 4\n",
    "            elif n + 3 <= length and max(numbers[n:n + 3:]) <= 511:\n",
    "                bytes_list.append(self.encode_chunk(numbers[n:n + 3:]))\n",
    "                n += 3\n",
    "            elif n + 2 <= length and max(numbers[n:n + 2:]) <= 2**14 - 1:\n",
    "                bytes_list.append(self.encode_chunk(numbers[n:n + 2:]))\n",
    "                n += 2\n",
    "            else:\n",
    "                bytes_list.append(self.encode_chunk([numbers[n]]))\n",
    "                n += 1\n",
    "         \n",
    "        return b''.join(bytes_list)\n",
    "        \n",
    "    def unpack(self, packed):\n",
    "        numbers = []\n",
    "        n = 0\n",
    "        stream = struct.unpack('%dI' % (len(packed) // 4), packed)\n",
    "        for chunk in stream:\n",
    "            length = self.coded[chunk >> 28]\n",
    "            for i in range(length):\n",
    "                n = (chunk >> ((28 // length) * i)) % (1 << (28 // length))\n",
    "                numbers.append(n)\n",
    "                \n",
    "        return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = ['lenta.ru_159b9f4b-972b-48b1-8ec3-44fbd6be33c4_01.gz']\n",
    "\n",
    "class DocStreamReader:\n",
    "    def __init__(self, paths):\n",
    "        self.paths = paths\n",
    "\n",
    "    def open_single(self, path):\n",
    "        return gzip.open(path, 'rb') if path.endswith('.gz') else open(path, 'rb')\n",
    "\n",
    "    def __iter__(self):\n",
    "        for path in self.paths:\n",
    "            with self.open_single(path) as stream:\n",
    "                while True:\n",
    "                    sb = stream.read(4)\n",
    "                    if len(sb) == 0:\n",
    "                        break\n",
    "\n",
    "                    size = struct.unpack('i', sb)[0]\n",
    "                    msg = stream.read(size)\n",
    "                    doc = document_pb2.document()\n",
    "                    doc.ParseFromString(msg)\n",
    "                    yield doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexCreator:\n",
    "    def __init__(self, pack_type='varbyte'):\n",
    "        self.doc_to_url = {}\n",
    "        self.index = {}\n",
    "        self.pack_type = pack_type\n",
    "            \n",
    "        self.SPLIT_RGX = re.compile(r'\\w+', re.U)\n",
    "    \n",
    "    def create_index(self, docs):\n",
    "        for doc_id, doc in enumerate(docs):\n",
    "            terms = set(pymorphy_tokenizer(re.findall(self.SPLIT_RGX, doc.text.lower())))\n",
    "            self.doc_to_url[doc_id] = doc.url\n",
    "            \n",
    "            for term in terms:\n",
    "                if term in self.index.keys():\n",
    "                    self.index[term].append(doc_id)\n",
    "                else:\n",
    "                    self.index[term] = array.array('I', [doc_id])\n",
    "        \n",
    "        return self.index, self.doc_to_url\n",
    "    \n",
    "    def compress_index(self):\n",
    "        unpacked_size = 0\n",
    "        packed_size = 0\n",
    "        \n",
    "        for term in self.index:\n",
    "            posting_list = self.index[term]\n",
    "            \n",
    "            #храним промежутки, а не сами числа\n",
    "            unpacked = [posting_list[0]]\n",
    "            for i in range(len(posting_list) - 1):\n",
    "                unpacked.append(posting_list[i + 1] - posting_list[i])\n",
    "            \n",
    "            packed = b''\n",
    "            if self.pack_type == 'varbyte':\n",
    "                packer = Varbyte()\n",
    "                packed = packer.pack(unpacked)\n",
    "            elif self.pack_type == 'simple9':\n",
    "                packer = Simple9()\n",
    "                packed = packer.pack(unpacked)\n",
    "                \n",
    "            unpacked_size += sys.getsizeof(posting_list)\n",
    "            packed_size += sys.getsizeof(packed)\n",
    "            self.index[term] = packed\n",
    "            \n",
    "        print(unpacked_size)\n",
    "        print(packed_size)\n",
    "            \n",
    "    def save_index(self):\n",
    "        path = 'index.gz'\n",
    "        if self.pack_type is not None:\n",
    "            path = self.pack_type + '_' + path\n",
    "            \n",
    "        with gzip.open(path, 'wb') as stream:\n",
    "            for term in self.index:\n",
    "                tb = bytes(term, 'utf-8')\n",
    "                stream.write(struct.pack('I', len(tb)))\n",
    "                stream.write(tb)\n",
    "                stream.write(struct.pack('I', len(self.index[term])))\n",
    "                stream.write(self.index[term])\n",
    "                \n",
    "        path = 'docs_url.gz'\n",
    "        with gzip.open(path, 'wb') as stream:\n",
    "            for doc_id in self.doc_to_url:\n",
    "                stream.write(struct.pack('I', doc_id))\n",
    "                ub = bytes(self.doc_to_url[doc_id], 'utf-8')\n",
    "                stream.write(struct.pack('I', len(ub)))\n",
    "                stream.write(ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array('I', [23, 50, 205, 249, 498, 576, 761, 762, 973, 1023, 1037, 1223])\n",
      "http://lenta.ru/culture/2002/12/26/mult/\n",
      "2514156\n",
      "1058551\n"
     ]
    }
   ],
   "source": [
    "reader = DocStreamReader(PATHS)\n",
    "# for doc in reader:\n",
    "#     print(doc.url, len(doc.text))\n",
    "index_creator = IndexCreator('varbyte')\n",
    "index, url = index_creator.create_index(reader)\n",
    "\n",
    "print(index['абсолютно'])\n",
    "print(url[index['абсолютно'][0]])\n",
    "\n",
    "index_creator.compress_index()\n",
    "index_creator.save_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_dict.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 27, 155, 44, 249, 78, 185, 1, 211, 50, 14, 186]\n"
     ]
    }
   ],
   "source": [
    "test = [23, 27, 155, 44, 249, 78, 185, 1, 211, 50, 14, 186]\n",
    "packer = Varbyte()\n",
    "packed = packer.pack(test)\n",
    "unpacked = packer.unpack(packed)\n",
    "print(unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    def __init__(self):\n",
    "        path = 'varbyte_index.gz'\n",
    "        self.pack_type = 'varbyte'\n",
    "        \n",
    "        if os.path.exists('simple9_index.gz'):\n",
    "            path = 'simple9_index.gz'\n",
    "            self.pack_type = 'simple9'\n",
    "            \n",
    "        self.index = {}\n",
    "        with gzip.open(path, 'rb') as stream:\n",
    "            while True:\n",
    "                sb = stream.read(4)\n",
    "                if len(sb) == 0:\n",
    "                    break\n",
    "                    \n",
    "                size = struct.unpack('I', sb)[0]\n",
    "                term = stream.read(size).decode('utf-8')\n",
    "                \n",
    "                sb = stream.read(4)\n",
    "                size = struct.unpack('I', sb)[0]\n",
    "                posting_list = stream.read(size)\n",
    "                \n",
    "                self.index[term] = posting_list\n",
    "    \n",
    "    def urls(self):\n",
    "        path = 'docs_url.gz'\n",
    "        \n",
    "        self.docs_url = {}\n",
    "        with gzip.open(path, 'rb') as stream:\n",
    "            while True:\n",
    "                sb = stream.read(4)\n",
    "                if len(sb) == 0:\n",
    "                    break\n",
    "                    \n",
    "                doc_id = struct.unpack('I', sb)[0]\n",
    "                \n",
    "                sb = stream.read(4)\n",
    "                size = struct.unpack('I', sb)[0]\n",
    "                url = stream.read(size).decode('utf-8')\n",
    "                \n",
    "                self.docs_url[doc_id] = url\n",
    "        \n",
    "        return self.docs_url\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        item = next(pymorphy_tokenizer([item]))\n",
    "        packed = self.index[item]\n",
    "        posting_list = []\n",
    "        \n",
    "        if self.pack_type == 'varbyte':\n",
    "            packer = Varbyte()\n",
    "            posting_list = packer.unpack(packed)\n",
    "        elif self.pack_type == 'Simple9':\n",
    "            packer = Simple9()\n",
    "            posting_list = packer.unpack(packed)\n",
    "            \n",
    "        for i in range(len(posting_list) - 1):\n",
    "            posting_list[i + 1] += posting_list[i]\n",
    "            \n",
    "        return posting_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, string, dictionary = None):\n",
    "        self.string = string\n",
    "        self.index = 0\n",
    "        self.dictionary = dictionary\n",
    "\n",
    "    def get_value(self):\n",
    "        value = self.parse_expression()\n",
    "        self.skip_whitespace()\n",
    "\n",
    "        return value\n",
    "\n",
    "    def peek(self):\n",
    "        return self.string[self.index:self.index + 1]\n",
    "\n",
    "    def has_next(self):\n",
    "        return self.index < len(self.string)\n",
    "\n",
    "    def is_next(self, value):\n",
    "        return self.string[self.index:self.index + len(value)] == value\n",
    "\n",
    "    def pop_if_next(self, value):\n",
    "        if self.is_next(value):\n",
    "            self.index += len(value)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def pop_expected(self, value):\n",
    "        if not self.pop_if_next(value):\n",
    "            raise Exception(\"Expected '\" + value + \"' at index \" + str(self.index))\n",
    "\n",
    "    def skip_whitespace(self):\n",
    "        while self.has_next():\n",
    "            if self.peek() in ' \\t\\n\\r':\n",
    "                self.index += 1\n",
    "            else:\n",
    "                return\n",
    "\n",
    "    def parse_expression(self):\n",
    "        return self.parse_or()\n",
    "    \n",
    "    def parse_or(self):\n",
    "        values = [self.parse_and()]\n",
    "        \n",
    "        while True:\n",
    "            self.skip_whitespace()\n",
    "            char = self.peek()\n",
    "            \n",
    "            if char == '|':\n",
    "                self.index += 1\n",
    "                values.append(self.parse_and())\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        value = values[0]\n",
    "        \n",
    "        for factor in values[1::]:\n",
    "            value = union(value, factor)\n",
    "        return value\n",
    "\n",
    "    def parse_and(self):\n",
    "        values = [self.parse_parenthesis()]\n",
    "            \n",
    "        while True:\n",
    "            self.skip_whitespace()\n",
    "            char = self.peek()\n",
    "                \n",
    "            if char == '&':\n",
    "                self.index += 1\n",
    "                values.append(self.parse_parenthesis())\n",
    "            else:\n",
    "                break\n",
    "                     \n",
    "        value = values[0]\n",
    "        \n",
    "        for factor in values[1::]:\n",
    "            value = intersection(value, factor)\n",
    "        return value\n",
    "\n",
    "    def parse_parenthesis(self):\n",
    "        self.skip_whitespace()\n",
    "        char = self.peek()\n",
    "        \n",
    "        if char == '(':\n",
    "            self.index += 1\n",
    "            value = self.parse_expression()\n",
    "            self.skip_whitespace()\n",
    "            \n",
    "            if self.peek() != ')':\n",
    "                raise Exception(\"No closing parenthesis found at character \" + str(self.index))\n",
    "            self.index += 1\n",
    "            return value\n",
    "        else:\n",
    "            return self.parse_not()\n",
    "\n",
    "    def parse_arguments(self):\n",
    "        args = []\n",
    "        self.skip_whitespace()\n",
    "        self.popExpected('(')\n",
    "        while not self.pop_if_next(')'):\n",
    "            self.skip_whitespace()\n",
    "            if len(args) > 0:\n",
    "                self.pop_expected(',')\n",
    "                self.skip_whitespace()\n",
    "            args.append(self.parse_expression())\n",
    "            self.skip_whitespace()\n",
    "        return args\n",
    "\n",
    "    def parse_not(self):\n",
    "        self.skip_whitespace()\n",
    "        char = self.peek()\n",
    "        \n",
    "        if char == '!':\n",
    "            self.index += 1\n",
    "            return self.parse_parenthesis()\n",
    "        else:\n",
    "            return self.parse_value()\n",
    "\n",
    "    def parse_value(self):\n",
    "        self.skip_whitespace()\n",
    "        var = []\n",
    "        while self.has_next():\n",
    "            char = self.peek()\n",
    "            \n",
    "            if char.lower() in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz0123456789':\n",
    "                var.append(char)\n",
    "                self.index += 1\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        var = ''.join(var)\n",
    "        return self.dictionary[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 50, 205, 249, 498, 576, 761, 762, 973, 1023, 1037, 1223]\n",
      "[443]\n"
     ]
    }
   ],
   "source": [
    "index = Index()\n",
    "urls = index.urls()\n",
    "print(index['абсолютно'])\n",
    "print(index['редкость'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 50, 205, 249, 498, 576, 761, 762, 973, 1023, 1037, 1223]\n",
      "[443]\n",
      "[443]\n",
      "[23, 50, 205, 249, 443, 498, 576, 761, 762, 1023, 1223]\n",
      "['http://lenta.ru/culture/2002/12/26/mult/', 'http://lenta.ru/conf/tsepliaeva', 'http://lenta.ru/sport/2003/12/09/prize/', 'http://lenta.ru/news/2008/01/21/lutcenko/', 'http://lenta.ru/articles/2015/06/16/jfriske/', 'http://lenta.ru/news/2008/02/20/u2/', 'http://lenta.ru/most/2001/04/21/gusinsky/', 'http://lenta.ru/news/2014/07/29/osce1/', 'http://lenta.ru/articles/2014/11/18/granprirussia/', 'http://lenta.ru/articles/2006/09/04/players/', 'http://lenta.ru/news/2006/04/17/techno/', 'http://lenta.ru/news/2012/10/05/denin1/', 'http://lenta.ru/columns/2012/05/16/georgia/']\n"
     ]
    }
   ],
   "source": [
    "test1 = 'абсолютно'\n",
    "test2 = 'слова & редкость'\n",
    "test3 = '(слово | абсолютно) & редкость'\n",
    "test4 = '(слово & абсолютно) | редкости'\n",
    "\n",
    "print(Parser(test1, index).get_value())\n",
    "print(Parser(test2, index).get_value())\n",
    "print(Parser(test3, index).get_value())\n",
    "print(Parser(test4, index).get_value())\n",
    "\n",
    "test5 = '(словом & редкостью) | (словами & абсолютно) | абсолютно'\n",
    "result = [urls[i] for i in Parser(test5, index).get_value()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
